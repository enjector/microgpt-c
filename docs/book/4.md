# Chapter 4: The Organelle Concept – From Stem Cells to Specialists

## Introduction

This chapter introduces a pivotal idea that elevates MicroGPT-C from a single-model tool to a framework for composable intelligence: the *organelle*. Drawing from biology, where organelles are specialized structures within a cell—each performing a focused function—we apply the same principle to AI. An organelle in MicroGPT-C is a small, specialized model that starts as a generic "stem cell" (a blank transformer) and differentiates into an expert through targeted training.

The organelle API lives in `src/microgpt_organelle.h` and `src/microgpt_organelle.c`. This chapter explains how to create organelles, the differentiation process, and ensemble voting for reliability. The power lies in focus: a 460,000-parameter organelle trained on one task often outperforms a larger generalist on that same task, using fewer resources.

## The Stem Cell Model: A Blank Slate

At its core, an organelle is a lightweight transformer model, typically with 1-4 layers and embeddings of 48-96 dimensions, totaling 64,000 to 460,000 parameters. This "stem cell" state is undifferentiated—capable of learning any pattern but expert in none until trained.

Background: In biology, stem cells respond to chemical signals to specialize. In AI, the "signal" is the training corpus—a curated dataset of examples. The model adjusts parameters via backpropagation (computing gradients to minimize loss, as in Chapter 3) to memorize and generalize from the corpus.

Example Scenario: Start with a blank model. Feed it a corpus of greetings ("Hello", "Hi", "Greetings"). After training, it generates similar phrases. This is differentiation: from general predictor to greeting specialist.

Math Verification: Parameter count scales with dimensions. For embeddings d=96, layers l=4, heads h=8: Total params ≈ l * (3*d²/h + 4*d²) + vocab*d (simplified). At small scale, this fits in <2 MB, trainable in minutes on a laptop.

Pros of Small Size: Low memory (edge-friendly), fast convergence (fewer params to tune). Cons: Limited capacity—hence the need for specialization.

## Differentiation: Training for Expertise

Differentiation turns the stem cell into a specialist through targeted corpora and training.

### Corpus Generation

A corpus is a collection of input-output pairs, like "prompt|response". For reliability, generate thousands via algorithms (e.g., simulations) rather than manual collection.

Scenario: For a puzzle solver, simulate games: "board state|best move". Run 5,000 simulations to create pairs. This ensures coverage without real-world data biases.

Background: Good corpora are balanced, diverse, and noise-free. Imbalance (e.g., more "wins" than "losses") skews the model.

In MicroGPT-C, load corpora as text files, tokenize (Chapter 2), and train in loops.

### Retrieval vs. Generation

Organelles excel at *retrieval*: reproducing patterns from training, not true invention. A model trained on 2,000 functions retrieves them byte-perfectly but struggles with unseen combos.

Verification Example: Corpus with "add:1+2=3", "add:3+4=7". Inference on "add:5+6=" yields ~11 (retrieved pattern), not random.

Math: Overfitting measure—train loss near 0 means memorization. Test on held-out data: if loss spikes, it's retrieval-bound.

Scenario: Code assistant. Train on library functions; it retrieves "sort array" accurately. For novelty, combine organelles (next chapters).

### Capacity Scaling

Small models hit limits; scaling (e.g., d=48→96, l=2→4) boosts performance.

Example: Parsing outputs (extracting numbers). At 64,000 params, 31% success; at 460,000, 95%. 7x params cut errors 91%.

Math: Parameters ∝ d² * l. Doubling d quadruples some matrices, but quality scales sublinearly—diminishing returns past 500,000.

Scenario: Game move predictor. Small capacity misses threats; scaled catches 90% wins.

### Beyond 500K: The LR Scheduling Threshold

Scaling beyond 500K parameters introduces a new challenge: training instability. The c_compose experiment scaled to 1.2M parameters and **diverged** at the default learning rate (lr=0.001, warmup=100 steps). Two hyperparameter changes fixed it:

- **Halved peak lr** (0.001→0.0005): More parameters create more gradient signal; smaller steps prevent overshooting.
- **Extended warmup** (100→2500 steps, 5% of total): Gives Adam's moment estimates time to stabilise.

Rule of thumb: lr ∝ 1/√params. See Chapter 3 for the full case study and `docs/foundation/TRAINING_STRATEGIES.md` for guidelines.

## Ensemble Voting: Boosting Reliability

Single inferences can err; ensembles run multiple times with variation, voting on the best.

Background: Like asking three experts and taking majority. Vary temperature (Chapter 3) slightly (±0.05) for diversity.

Formula: Run n=3-5 inferences. Count matches; winner is mode. Confidence = votes_for_winner / n.

Verification: On ambiguous prompt, single run: 50% invalid. Ensemble: 90% valid (noise averages out).

Scenario: Direction chooser ("up,down,left,right"). Corpus teaches constraints; ensemble filters noise, achieving zero invalids.

Math Check: If single error rate p=0.5, binomial prob of majority wrong in n=3: <0.5. Drops to 0.125.

## Valid-Move Filtering and Fallbacks

Pre-filter prompts with valid options (e.g., "valid=up,left") to guide generation.

Fallback: If output invalid, pick first valid.

Scenario: Board game. Filter ensures legal moves; fallback rescues parses.