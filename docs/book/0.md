# MicroGPT-C: Technical Guide

**Title:** MicroGPT-C: Composable Intelligence at the Edge  

**Subtitle:** From Stem Cell Models to Real-World AI Pipelines – Architecture, Implementation, and Research  

This guide provides a technical walkthrough of MicroGPT-C: a zero-dependency C99 transformer framework for composable, sub-1M parameter AI at the edge. It assumes the reader has the repository alongside and basic C programming knowledge.

# Detailed Chapters Overview

The guide is structured as a progressive reference, starting with foundational concepts and building toward advanced applications and research. Each chapter includes code references, mathematical verification, and pointers to specific source files and project documentation.

### Part I: Foundations – Understanding the Core Framework

1. **Chapter 1: The Case for Small AI**  
   Why massive LLMs are unsustainable for edge devices and how MicroGPT-C provides a zero-dependency C99 alternative. Covers the "generalist monolith" problem, the stem cell analogy, and the value of specialized, composable models.  
   Key Topics: AI accessibility challenges; memory/compute math for edge devices; end-to-end research preview.

2. **Chapter 2: Core Architecture of MicroGPT-C**  
   The GPT-2-style transformer implementation in `src/microgpt.h` and `src/microgpt.c`. Covers tokenization (character-level and word-level), multi-head attention with causal masking, ReLU-activated feed-forward layers, RMSNorm with pre-normalization, and the Adam optimizer. References `docs/foundation/ATTENTION_MECHANISMS.md` for planned attention variants.  
   Key Topics: Parameter-efficient design; forward/backward passes; pre-norm block order; sub-1M parameter scaling.

3. **Chapter 3: Training and Inference Fundamentals**  
   Training loops, cross-entropy loss, learning rate scheduling (warmup + cosine decay), KV caching (including paged variants via `MICROGPT_PAGED_KV`), and reproducibility via seeded PRNG. References `docs/foundation/TRAINING_STRATEGIES.md`.  
   Key Topics: On-device training; handling catastrophic forgetting; checkpointing and resume.

### Part II: Building Organelles – Specialization and Composition

4. **Chapter 4: The Organelle Concept – From Stem Cells to Specialists**  
   The organelle API (`src/microgpt_organelle.h`, `src/microgpt_organelle.c`) and the differentiation process. Covers corpus generation, retrieval-based intelligence, ensemble voting, valid-move filtering, capacity scaling (64K to 460K params), and the 3-tier parameter right-sizing strategy (30K–160K). References `docs/organelles/ORGANELLE_VISION.md`.  
   Key Topics: Organelle training and inference; ensemble confidence; fallback mechanisms; parameter-corpus matching.

5. **Chapter 5: Pipeline Coordination – The Kanban Architecture**  
   The Organelle Pipeline Architecture (OPA) from `docs/organelles/ORGANELLE_PIPELINE.md`, including Kanban state management (`OpaKanban`), cycle detection (`OpaCycleDetector`), and the Planner-Worker-Judge decomposition. Uses game demos as case studies.  
   Key Topics: "Coordination rescues weakness"; invalid move filtering; oscillation breaking and replanning.

6. **Chapter 6: Logic Games as Research Laboratories**  
   Why games are ideal for testing OPA. Analyses eleven game demos from `experiments/organelles/`: 8-Puzzle, Tic-Tac-Toe, Connect-4, Lights Out, Mastermind, Klotski, Sudoku, Othello, Hex, Pentago, and Red Donkey. Covers decomposition patterns, win rate metrics, the game portfolio progression from simple puzzles to complex adversarial domains, and the parameter right-sizing experiment (3-tier: 30K/92K/160K) with findings that 4 of 8 games improved with 65–93% fewer parameters. References `docs/organelles/ORGANELLE_GAMES.md`.  
   Key Topics: Controlled testing environments; 11-game validation of OPA; parameter right-sizing; transferring game insights to real domains.

### Part III: Optimizations and Advanced Techniques

7. **Chapter 7: Optimization Strategies for Edge Deployment**  
   CPU SIMD vectorization, BLAS integration (`MICROGPT_BLAS`), GPU offloading via Metal (`src/microgpt_metal.h`, `src/microgpt_metal.m`), INT8 quantization (`QUANTIZATION_INT8`), and memory footprint management. References `docs/foundation/OPTIMISATION_STRATEGIES.md`.  
   Key Topics: Small-scale tradeoffs (CPU beats GPU below 512 embed dim); tiled matmul; dispatch overhead.

8. **Chapter 8: Attention Mechanisms and Scaling**  
   Implemented MHA and its scaling properties. Planned extensions: GQA and SWA (documented in `docs/foundation/ATTENTION_MECHANISMS.md` but not yet in `src/microgpt.c`). Covers memory vs. quality tradeoffs and long-context handling.  
   Key Topics: KV cache efficiency; scaling embed/layers/context; planned MLA integration.

9. **Chapter 9: Tooling and Workflow – From Research to Production**  
   Benchmarking, testing strategies (`tests/`), corpus management, multi-threaded training (`src/microgpt_thread.h`), and the planned CLI. Covers reproduction via seeding and automated workflows.  
   Key Topics: Reproducibility; profiling; the planned CLI tool (see ROADMAP.md).

### Part IV: Real-World Applications and Future Directions

10. **Chapter 10: Code Generation and Structured Outputs**  
    Autonomous code synthesis using `c_codegen`, `c_wiringgen`, and `c_compose` experiments. The c_compose pipeline (Planner→Judge, 1.2M params with LR scheduling) achieves **83% exact match** on function composition plans. Covers flat-string protocols from `docs/organelles/ORGANELLE_PIPELINE.md`, paraphrase blindness mitigation, and confidence gating.  
    Key Topics: Composition accuracy; pipeline-based code generation; LR scheduling for larger models; structured output validation.

11. **Chapter 11: Edge AI Applications – Sensors, IoT, and Beyond**  
    Applying OPA to sensors, IoT, and robotics. Covers on-device adaptation and conceptual federated differentiation patterns. Discusses deploying on ESP32 and similar microcontrollers.  
    Key Topics: Anomaly detection; real-time inference; privacy via local training.

12. **Chapter 12: Ethical Considerations and Safeguards**  
    Risks (overconfidence, data bias, privacy leaks) and mitigations (curated corpora, judge patterns, confidence thresholds, drift detection). References the safety approach from `README.md`.  
    Key Topics: Bias auditing; validation loops; transparency via attention inspection.

13. **Chapter 13: Future Research and Extensions**  
    Research proposals aligned with `ROADMAP.md`: organelle marketplace, self-monitoring, hardware targets (RISC-V, FPGA), hybrid approaches (search + transformers), and open questions (trap signals, lookahead, A* integration).  
    Key Topics: Scaling to 1M+ params; DAG pipelines; community contributions.

### Appendices
- **Appendix A: Glossary and References** – Key terms (e.g., kanban, OPA) and citations to foundational papers.
